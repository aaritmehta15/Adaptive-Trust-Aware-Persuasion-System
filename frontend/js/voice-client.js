/**
 * VoiceClient â€” Browser-side voice integration for ATLAS.
 *
 * Two-AudioContext architecture (matches Google ADK bidi-demo reference):
 *
 *   recorderContext (16kHz)
 *     â””â”€â”€ getUserMedia stream â†’ pcm-recorder-processor worklet
 *           â””â”€â”€ port.onmessage â†’ Float32 frames â†’ sendAudio() â†’ WebSocket
 *
 *   playerContext (24kHz)  â† matches Gemini native audio output rate
 *     â””â”€â”€ pcm-player-processor worklet (ring buffer: 60 s Ã— 24kHz)
 *           â””â”€â”€ connected to playerContext.destination â†’ speakers
 *
 * This separation ensures:
 *   - Mic is captured at the exact rate Gemini expects (16kHz)
 *   - Playback runs at the exact rate Gemini produces (24kHz)
 *   - Mic audio is NOT looped back through the speakers
 *   - No unintended resampling by the browser
 */
class VoiceClient {
    constructor() {
        this.websocket = null;

        // Two separate AudioContexts â€” one per direction
        this.recorderContext = null;   // 16 kHz  â€” mic capture only
        this.playerContext = null;   // 24 kHz  â€” server audio playback only

        this.recorderNode = null;      // pcm-recorder-processor worklet node
        this.playerNode = null;      // pcm-player-processor worklet node

        this.mediaStream = null;       // Raw getUserMedia stream (for cleanup)
        this.isActive = false;
    }

    // â”€â”€ Session ID â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    _generateSessionId() {
        return 'voice_' + Math.random().toString(36).substring(2, 14);
    }

    // â”€â”€ Start â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async start() {
        if (this.isActive) return;

        try {
            console.log('ðŸŽ™ï¸ Starting Voice Client...');

            // â”€â”€ 1. Player AudioContext at 24kHz (Gemini output rate) â”€â”€â”€â”€â”€â”€â”€
            this.playerContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 24000,
                latencyHint: 'interactive',
            });
            console.log(`ðŸ”Š Player AudioContext: sampleRate=${this.playerContext.sampleRate}`);
            await this.playerContext.audioWorklet.addModule('js/audio-player-processor.js');

            this.playerNode = new AudioWorkletNode(this.playerContext, 'pcm-player-processor');
            this.playerNode.connect(this.playerContext.destination);

            // â”€â”€ 2. Recorder AudioContext at 16kHz (Gemini input rate) â”€â”€â”€â”€â”€
            this.recorderContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 16000,
                latencyHint: 'interactive',
            });
            console.log(`ðŸŽ¤ Recorder AudioContext: sampleRate=${this.recorderContext.sampleRate}`);
            await this.recorderContext.audioWorklet.addModule('js/audio-processor.js');

            // â”€â”€ 3. Microphone (captured at 16kHz via recorderContext) â”€â”€â”€â”€â”€
            this.mediaStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                }
            });

            const source = this.recorderContext.createMediaStreamSource(this.mediaStream);
            this.recorderNode = new AudioWorkletNode(this.recorderContext, 'pcm-recorder-processor');

            // Mic frames arrive as Float32 at 16kHz â†’ convert and send upstream
            this.recorderNode.port.onmessage = (event) => {
                this.sendAudio(event.data); // event.data is a copied Float32Array
            };

            // Recorder chain: mic â†’ recorder worklet (NOT connected to destination)
            source.connect(this.recorderNode);
            // NOTE: recorderNode intentionally NOT connected to destination â€” no mic loopback

            // â”€â”€ 4. WebSocket â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            const sessionId = this._generateSessionId();
            const baseUrl = (window.DEPLOYED_API_URL || 'http://localhost:8000').replace('http', 'ws');
            const wsUrl = `${baseUrl}/ws/voice/${sessionId}`;
            console.log(`ðŸ”Œ Connecting to: ${wsUrl}`);
            this.websocket = new WebSocket(wsUrl);

            this.websocket.onopen = () => {
                console.log('âœ… Voice WebSocket Connected');
                this.isActive = true;
                this.updateUI(true);
            };

            this.websocket.onmessage = async (event) => {
                try {
                    const msg = JSON.parse(event.data);
                    if (msg.type === 'audio') {
                        this.playAudio(msg.data);
                    } else if (msg.type === 'interrupted') {
                        console.log('â— Interrupted â€” clearing audio buffer');
                        this.clearAudioBuffer();
                    } else if (msg.type === 'turn_complete') {
                        console.log('âœ… Agent turn complete');
                    } else if (msg.type === 'error') {
                        console.error('ðŸ”´ Server Error:', msg.message);
                    }
                } catch (e) {
                    console.error('Message parse error:', e);
                }
            };

            this.websocket.onclose = (event) => {
                console.log(`ðŸ”Œ Voice WebSocket Closed (code: ${event.code})`);
                this.stop();
            };

            this.websocket.onerror = (error) => {
                console.error('âŒ WebSocket Error:', error);
            };

            console.log('ðŸŽ¤ Microphone active, streaming audio at 16kHz...');

        } catch (e) {
            console.error('âŒ Failed to start voice client:', e);
            alert('Could not start voice mode: ' + e.message);
            this.stop();
        }
    }

    // â”€â”€ Stop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    stop() {
        this.isActive = false;
        this.updateUI(false);

        if (this.websocket) {
            try { this.websocket.close(); } catch (_) { }
            this.websocket = null;
        }
        if (this.mediaStream) {
            this.mediaStream.getTracks().forEach(track => track.stop());
            this.mediaStream = null;
        }
        if (this.recorderContext) {
            try { this.recorderContext.close(); } catch (_) { }
            this.recorderContext = null;
        }
        if (this.playerContext) {
            try { this.playerContext.close(); } catch (_) { }
            this.playerContext = null;
        }
        this.recorderNode = null;
        this.playerNode = null;
        console.log('ðŸ›‘ Voice client stopped.');
    }

    // â”€â”€ Upstream: mic â†’ server â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    /**
     * Convert Float32 (from 16kHz recorderContext) â†’ Int16 â†’ Base64 â†’ WebSocket.
     * float32Array is already a copy (made in audio-processor.js), safe to read.
     */
    sendAudio(float32Array) {
        if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) return;

        // Float32 â†’ Int16 (signed, symmetric clamp)
        const int16Array = new Int16Array(float32Array.length);
        for (let i = 0; i < float32Array.length; i++) {
            const s = Math.max(-1, Math.min(1, float32Array[i]));
            int16Array[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }

        // Int16 binary â†’ Base64
        const uint8 = new Uint8Array(int16Array.buffer);
        let binary = '';
        for (let i = 0; i < uint8.byteLength; i++) {
            binary += String.fromCharCode(uint8[i]);
        }

        this.websocket.send(JSON.stringify({
            mime_type: 'audio/pcm',
            data: btoa(binary),
        }));
    }

    // â”€â”€ Downstream: server â†’ speaker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    /**
     * Decode Base64 audio from server â†’ Int16Array â†’ player worklet ring buffer.
     * Server sends audio/pcm;rate=24000 Int16 mono little-endian.
     */
    playAudio(base64Data) {
        console.log(`ðŸ”Š Received audio chunk: ${base64Data.length} base64 chars`);
        const binaryString = atob(base64Data);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }
        // Reinterpret raw bytes as Int16 (little-endian, as sent by Gemini)
        const int16Data = new Int16Array(bytes.buffer);
        console.log(`   â†’ ${int16Data.length} Int16 samples (${(int16Data.length / 24000).toFixed(3)}s at 24kHz)`);

        if (this.playerNode) {
            // Transfer Int16Array to worklet â€” postMessage with transferable
            // (Int16Array is a view, transfer the underlying buffer)
            const transferBuffer = int16Data.buffer.slice(0); // own copy
            const transferArray = new Int16Array(transferBuffer);
            this.playerNode.port.postMessage(transferArray, [transferBuffer]);
        }
    }

    // â”€â”€ Buffer clear (on interruption) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    clearAudioBuffer() {
        if (this.playerNode) {
            this.playerNode.port.postMessage({ command: 'clear' });
        }
    }

    // â”€â”€ UI helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    updateUI(active) {
        const btn = document.getElementById('voice-mode-btn');
        if (btn) {
            btn.textContent = active ? 'ðŸ”´ Stop Voice' : 'ðŸŽ™ï¸ Start Voice';
            btn.style.backgroundColor = active ? '#ff4444' : '';
        }
        const inputContainer = document.querySelector('.chat-input-container');
        if (inputContainer) {
            inputContainer.style.display = active ? 'none' : 'flex';
        }
    }
}

window.voiceClient = new VoiceClient();
